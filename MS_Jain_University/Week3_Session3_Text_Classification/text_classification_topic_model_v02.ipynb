{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proprietary content. Â©Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification using topic models as X variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enalapril</td>\n",
       "      <td>4</td>\n",
       "      <td>enalapril management of congestive heart failu...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>1</td>\n",
       "      <td>ortho-tri-cyclen birth prevention - Although t...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ponstel</td>\n",
       "      <td>10</td>\n",
       "      <td>ponstel menstrual cramps - I was used to havin...</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prilosec</td>\n",
       "      <td>3</td>\n",
       "      <td>prilosec acid reflux - The acid reflux went aw...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lyrica</td>\n",
       "      <td>2</td>\n",
       "      <td>lyrica fibromyalgia - I think that the Lyrica ...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        urlDrugName  rating  \\\n",
       "0         enalapril       4   \n",
       "1  ortho-tri-cyclen       1   \n",
       "2           ponstel      10   \n",
       "3          prilosec       3   \n",
       "4            lyrica       2   \n",
       "\n",
       "                                              Review score  \n",
       "0  enalapril management of congestive heart failu...   Low  \n",
       "1  ortho-tri-cyclen birth prevention - Although t...   Low  \n",
       "2  ponstel menstrual cramps - I was used to havin...  high  \n",
       "3  prilosec acid reflux - The acid reflux went aw...   Low  \n",
       "4  lyrica fibromyalgia - I think that the Lyrica ...   Low  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4143, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df.score.apply(lambda x: 1 if x == \"high\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3241\n",
       "0     902\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text pre-processing\n",
    "\n",
    "#remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom stop words\n",
    "new_words = [\"some\",\"one\",\"like\",\"time\",\"br\",\"drug\",\"effect\",\"could\",\"good\",'even', 'get', 'would',\n",
    "             'make', 'really', 'see', 'well', 'much', 'great', 'first', 'people', 'also', 'bad', \n",
    "             'show', 'way', 'thing', 'made', 'go', 'think', 'know', 'watch','look','many','day']\n",
    "stop_words = stop_words.union(new_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_newline(series):\n",
    "    return [review.replace('\\n','') for review in series]\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "def remove_stopwords(texts):\n",
    "    out = [[word for word in simple_preprocess(str(doc))\n",
    "            if word not in stop_words]\n",
    "            for doc in texts]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(df):\n",
    "    df['Review'] = strip_newline(df.Review)\n",
    "    words = list(sent_to_words(df.Review))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[review] for review in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    \n",
    "    return corpus, id2word, bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply function to corpus to pre-process and extract bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus, train_id2word, bigram_train = get_corpus(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train = gensim.models.ldamulticore.LdaMulticore(\n",
    "                        corpus=train_corpus,\n",
    "                        num_topics=10,\n",
    "                        id2word=train_id2word,\n",
    "                        chunksize=100,\n",
    "                        workers=7, # Num. Processing Cores - 1\n",
    "                        passes=50,\n",
    "                        eval_every = 1,\n",
    "                        per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"treatment\" + 0.024*\"acne\" + 0.014*\"thyroid\" + 0.011*\"years\" + 0.010*\"medication\" + 0.009*\"taken\" + 0.009*\"synthroid\" + 0.009*\"taking\" + 0.008*\"daily\" + 0.008*\"none\" + 0.007*\"take\" + 0.007*\"levels\" + 0.007*\"months\" + 0.006*\"antibiotic\" + 0.006*\"since\"'),\n",
       " (1,\n",
       "  '0.015*\"take\" + 0.012*\"days\" + 0.012*\"started\" + 0.012*\"took\" + 0.012*\"doctor\" + 0.011*\"still\" + 0.010*\"went\" + 0.009*\"taking\" + 0.009*\"week\" + 0.009*\"eat\" + 0.009*\"never\" + 0.008*\"felt\" + 0.008*\"stomach\" + 0.007*\"got\" + 0.006*\"feel\"'),\n",
       " (2,\n",
       "  '0.060*\"skin\" + 0.025*\"acne\" + 0.019*\"use\" + 0.018*\"face\" + 0.015*\"used\" + 0.014*\"cream\" + 0.014*\"using\" + 0.011*\"dry\" + 0.010*\"applied\" + 0.009*\"redness\" + 0.009*\"product\" + 0.009*\"retin\" + 0.009*\"apply\" + 0.008*\"treatment\" + 0.007*\"eye\"'),\n",
       " (3,\n",
       "  '0.021*\"hair\" + 0.021*\"cholesterol\" + 0.014*\"blood\" + 0.013*\"hair_loss\" + 0.012*\"loss\" + 0.011*\"high\" + 0.010*\"taking\" + 0.010*\"diet\" + 0.010*\"daily\" + 0.010*\"lipitor\" + 0.009*\"level\" + 0.009*\"months\" + 0.009*\"mg\" + 0.009*\"levels\" + 0.008*\"lowered\"'),\n",
       " (4,\n",
       "  '0.033*\"depression\" + 0.016*\"mg\" + 0.015*\"felt\" + 0.014*\"feel\" + 0.013*\"life\" + 0.013*\"anxiety\" + 0.010*\"taking\" + 0.008*\"better\" + 0.008*\"mood\" + 0.007*\"feeling\" + 0.007*\"able\" + 0.007*\"months\" + 0.006*\"lexapro\" + 0.006*\"depressed\" + 0.005*\"helped\"'),\n",
       " (5,\n",
       "  '0.036*\"mg\" + 0.019*\"dose\" + 0.016*\"dosage\" + 0.015*\"medication\" + 0.014*\"increased\" + 0.013*\"patient\" + 0.012*\"treatment\" + 0.012*\"symptoms\" + 0.011*\"anxiety\" + 0.010*\"years\" + 0.008*\"daily\" + 0.007*\"prescribed\" + 0.007*\"started\" + 0.006*\"experienced\" + 0.006*\"reduced\"'),\n",
       " (6,\n",
       "  '0.025*\"infection\" + 0.020*\"days\" + 0.018*\"allergies\" + 0.016*\"symptoms\" + 0.014*\"asthma\" + 0.013*\"took\" + 0.012*\"rash\" + 0.010*\"taking\" + 0.010*\"cough\" + 0.010*\"none\" + 0.010*\"take\" + 0.008*\"taken\" + 0.008*\"zyrtec\" + 0.008*\"prednisone\" + 0.008*\"medication\"'),\n",
       " (7,\n",
       "  '0.076*\"pain\" + 0.014*\"severe\" + 0.010*\"take\" + 0.010*\"back\" + 0.009*\"surgery\" + 0.008*\"took\" + 0.008*\"medication\" + 0.007*\"swelling\" + 0.007*\"hot_flashes\" + 0.007*\"neck\" + 0.006*\"prescribed\" + 0.006*\"arthritis\" + 0.006*\"due\" + 0.006*\"taking\" + 0.005*\"patch\"'),\n",
       " (8,\n",
       "  '0.018*\"pill\" + 0.017*\"take\" + 0.016*\"blood_pressure\" + 0.015*\"pressure\" + 0.014*\"headache\" + 0.014*\"migraine\" + 0.012*\"taking\" + 0.012*\"migraines\" + 0.012*\"headaches\" + 0.011*\"period\" + 0.010*\"periods\" + 0.010*\"birth_control\" + 0.009*\"days\" + 0.008*\"every\" + 0.008*\"high_blood\"'),\n",
       " (9,\n",
       "  '0.036*\"sleep\" + 0.031*\"take\" + 0.023*\"night\" + 0.013*\"morning\" + 0.012*\"hours\" + 0.011*\"mg\" + 0.009*\"feel\" + 0.009*\"taking\" + 0.008*\"without\" + 0.008*\"bed\" + 0.008*\"insomnia\" + 0.008*\"work\" + 0.007*\"medication\" + 0.007*\"took\" + 0.006*\"able\"')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.print_topics(20,num_words=15)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract training vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(df)):\n",
    "    top_topics = (\n",
    "        lda_train.get_document_topics(train_corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    topic_vec.extend([len(df.iloc[i].Review)])\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0017864703,\n",
       " 0.0017866711,\n",
       " 0.0017862209,\n",
       " 0.0017862006,\n",
       " 0.0017864952,\n",
       " 0.0017864573,\n",
       " 0.0017863358,\n",
       " 0.16800493,\n",
       " 0.8177035,\n",
       " 0.0017867765,\n",
       " 712]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_vecs)\n",
    "y = np.array(df.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4143, 11) (4143,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2900, 11) (2900,)\n",
      "(1243, 11) (1243,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103, 172],\n",
       "       [179, 789]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7176186645213194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
