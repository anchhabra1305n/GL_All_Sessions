{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouZF_oN8SAS-"
   },
   "source": [
    "<h1>Case Study: Flowers CNN Classifier</h1>\n",
    "Flowers dataset (https://www.kaggle.com/alxmamaev/flowers-recognition) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCLdAkuKSLYa"
   },
   "source": [
    "*Make sure you activate Hardware accelerator in the settings. \n",
    "Go to Runtime --> Change runtime type --> Set Hardware Accelerator to GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJeWLYj_LpaI"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEB3KqhjSbJD"
   },
   "source": [
    "**Mounting Google Drive on to the Google Colab instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274949,
     "status": "ok",
     "timestamp": 1613652413051,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "DsCraWoxfIvp",
    "outputId": "73be9994-502e-482b-b5a6-14bd286c4b15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGGHMs7oNcwF"
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93cfwi25SlSF"
   },
   "source": [
    "**Set the appropriate path for the datsaet zip provided**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1613653187887,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "U2rV6UPvf9PV"
   },
   "outputs": [],
   "source": [
    "images_path = \"/content/drive/MyDrive/PM Document Repo/Currently Used Decks/Mentor Session Material/Module 9 - Computer Vision/Week 1 - CV  - Mentor deck/Copy of flowers.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF6IorgsSqG5"
   },
   "source": [
    "**Extracting the dataset.zip to the present working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7280,
     "status": "ok",
     "timestamp": 1613653198584,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "6fF2XlCnfhDD"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(images_path,'r') as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qCQB-4eSwMK"
   },
   "source": [
    "*Check the list of files in the pwd(present working directory) by running command 'ls' and ensure 'dataset' folder has been generated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1180,
     "status": "ok",
     "timestamp": 1613653260333,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "e_GB89vufuum",
    "outputId": "223434fa-cde9-4dbf-f5de-17e504de5bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  flowers\tsample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfoV8iFbTA52"
   },
   "source": [
    "**Importing required Keras modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1232,
     "status": "ok",
     "timestamp": 1613653507893,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "KpFyhikhgKHB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM6ARMO1TFw-"
   },
   "source": [
    "<h2>Building the CNN Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1613653802656,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "RLhlFr9vg8Qq"
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN classifier\n",
    "classifier = Sequential()\n",
    "\n",
    "# Add a Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Add a Max Pooling layer of size 2X2\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Adding another pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Adding another pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flattening the layer before fully connected layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer with 512 neurons\n",
    "classifier.add(Dense(units = 512, activation = 'relu'))\n",
    "\n",
    "# Adding dropout with probability 0.5\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Adding a fully connected layer with 128 neurons\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "\n",
    "# The final output layer with 5 neuron to predict the categorical classifcation\n",
    "classifier.add(Dense(units = 5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmlFKyBaToR2"
   },
   "source": [
    "**Compiling the CNN classifier with Adam optimizer (default Learning rate and other parameters)\n",
    "and Categorical Crossentropy as loss function and Accuracy as the metric to monitor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i97nysnzTuAZ"
   },
   "source": [
    "*Optionally you can use an optimizer with custom learning rate and passing it to the optimizer parameter of compile*\n",
    "\n",
    "*Eg: keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1613653856622,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "CtMbL_TvTnlp"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv0eDbXYUcgQ"
   },
   "source": [
    "**Dataset Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdKWE1o-UjB7"
   },
   "source": [
    "*ImageDataGenerator is a powerful preprocessing utility to generate training and \n",
    "testing data with common data augmentation techniques. It can also be used to  \n",
    "generate training data from Images stored in hierarchical directory structures\n",
    "For more options of ImageDataGenerator go to https://keras.io/preprocessing/image/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327255,
     "status": "ok",
     "timestamp": 1613654229563,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "1djMyebthCGP",
    "outputId": "2b661b3e-b8ff-44b4-d5d9-1232ac5e167e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3823 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "119/119 [==============================] - 23s 138ms/step - loss: 1.4854 - accuracy: 0.3380 - val_loss: 1.1589 - val_accuracy: 0.4875\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 16s 136ms/step - loss: 1.1459 - accuracy: 0.5275 - val_loss: 1.1126 - val_accuracy: 0.5292\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 16s 135ms/step - loss: 1.0254 - accuracy: 0.6039 - val_loss: 1.0891 - val_accuracy: 0.5292\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 16s 135ms/step - loss: 0.9488 - accuracy: 0.6331 - val_loss: 1.1369 - val_accuracy: 0.5437\n",
      "Epoch 5/20\n",
      "119/119 [==============================] - 16s 134ms/step - loss: 0.8868 - accuracy: 0.6696 - val_loss: 0.9763 - val_accuracy: 0.5708\n",
      "Epoch 6/20\n",
      "119/119 [==============================] - 16s 135ms/step - loss: 0.8695 - accuracy: 0.6748 - val_loss: 0.9264 - val_accuracy: 0.6125\n",
      "Epoch 7/20\n",
      "119/119 [==============================] - 16s 133ms/step - loss: 0.7892 - accuracy: 0.6946 - val_loss: 0.9599 - val_accuracy: 0.6083\n",
      "Epoch 8/20\n",
      "119/119 [==============================] - 16s 134ms/step - loss: 0.7566 - accuracy: 0.7169 - val_loss: 0.9408 - val_accuracy: 0.6104\n",
      "Epoch 9/20\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 0.7333 - accuracy: 0.7171 - val_loss: 0.9543 - val_accuracy: 0.6083\n",
      "Epoch 10/20\n",
      "119/119 [==============================] - 16s 135ms/step - loss: 0.7171 - accuracy: 0.7289 - val_loss: 0.9579 - val_accuracy: 0.6250\n",
      "Epoch 11/20\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 0.6597 - accuracy: 0.7409 - val_loss: 0.8664 - val_accuracy: 0.6250\n",
      "Epoch 12/20\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 0.6218 - accuracy: 0.7677 - val_loss: 0.8845 - val_accuracy: 0.6271\n",
      "Epoch 13/20\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 0.6097 - accuracy: 0.7824 - val_loss: 0.8360 - val_accuracy: 0.6417\n",
      "Epoch 14/20\n",
      "119/119 [==============================] - 16s 134ms/step - loss: 0.5941 - accuracy: 0.7741 - val_loss: 0.8906 - val_accuracy: 0.6417\n",
      "Epoch 15/20\n",
      "119/119 [==============================] - 16s 133ms/step - loss: 0.5812 - accuracy: 0.7833 - val_loss: 0.9042 - val_accuracy: 0.6229\n",
      "Epoch 16/20\n",
      "119/119 [==============================] - 16s 133ms/step - loss: 0.5379 - accuracy: 0.7943 - val_loss: 0.9577 - val_accuracy: 0.6292\n",
      "Epoch 17/20\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 0.5180 - accuracy: 0.7955 - val_loss: 0.9414 - val_accuracy: 0.6396\n",
      "Epoch 18/20\n",
      "119/119 [==============================] - 16s 136ms/step - loss: 0.5230 - accuracy: 0.8007 - val_loss: 0.9277 - val_accuracy: 0.6479\n",
      "Epoch 19/20\n",
      "119/119 [==============================] - 16s 136ms/step - loss: 0.4827 - accuracy: 0.8190 - val_loss: 0.9497 - val_accuracy: 0.6375\n",
      "Epoch 20/20\n",
      "119/119 [==============================] - 16s 134ms/step - loss: 0.4826 - accuracy: 0.8095 - val_loss: 0.9425 - val_accuracy: 0.6542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba2041cfd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Create data generator for training data with data augmentation and normalizing all\n",
    "# values by 255\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Setting training data generator's source directory\n",
    "# Setting the target size to resize all the images to (64,64) as the model input layer expects 32X32 images\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./flowers/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "# Setting testing data generator's source directory\n",
    "test_set = test_datagen.flow_from_directory('./flowers/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "# There are 3823 training images and 500 test images in total\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = int(3823/32),\n",
    "                         epochs = 20,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = int(500/32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "157MBWfwVORb"
   },
   "source": [
    "**Always save the model and its weights after training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1613654244324,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "WwvESxvvzRgz"
   },
   "outputs": [],
   "source": [
    "classifier.save('./classifier.h5')\n",
    "\n",
    "classifier.save_weights('./classifier_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw9MVESlVSq0"
   },
   "source": [
    "*Check the current directory if the weights have been saved*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1613654250944,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "pHkGYUnpzbVQ",
    "outputId": "8c70c2c8-c151-45f2-9d27-4f82abb461f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.h5  classifier_weights.h5  drive  flowers  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKfWmfnTVWbO"
   },
   "source": [
    "<h2>Let's test the model now</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRXKNJjWVzGq"
   },
   "source": [
    "**Load the pre-trained saved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1613654286544,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "tB5k1sCWVwJt"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the pre trained model from the HDF5 file saved previously\n",
    "pretrained_model = load_model('./classifier.h5')\n",
    "pretrained_model.load_weights('./classifier_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iFL22MKV-nB"
   },
   "source": [
    "**Testing the model on a test image from one of the test folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1613654296988,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "FLrGrFCJhCmq",
    "outputId": "dc934473-d936-4cb4-b341-943e20f9c5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "After expand_dims: (1, 64, 64, 3)\n",
      "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n",
      "[0.19680828 0.71740514 0.05897095 0.0025997  0.02421595]\n",
      "dandelion\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "test_image = cv2.imread('./flowers/test/daisy/100080576_f52e8ee070_n.jpg')\n",
    "# Resize the image to 64X64 shape to be compatible with the model\n",
    "test_image = cv2.resize(test_image,(64,64))\n",
    "\n",
    "# Check if the size of the Image array is compatible with Keras model\n",
    "print(test_image.shape)\n",
    "\n",
    "# If not compatible expand the dimensions to match with the Keras Input\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image =test_image*1/255.0\n",
    "\n",
    "#Check the size of the Image array again\n",
    "print('After expand_dims: '+ str(test_image.shape))\n",
    "\n",
    "\n",
    "#Predict the result of the test image\n",
    "result = classifier.predict(test_image)\n",
    "\n",
    "# Check the indices Image Data Generator has allotted to each folder\n",
    "classes_dict = training_set.class_indices\n",
    "print(classes_dict)\n",
    "\n",
    "# Creating a list of classes in test set for showing the result as the folder name\n",
    "prediction_class = []\n",
    "for class_name,index in classes_dict.items():\n",
    "  prediction_class.append(class_name)\n",
    "  \n",
    "print(result[0])\n",
    "\n",
    "# Index of the class with maximum probability\n",
    "predicted_index = np.argmax(result[0])\n",
    "\n",
    "# Print the name of the class\n",
    "print(prediction_class[predicted_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32IsbG8Ox2XN"
   },
   "source": [
    "**Generating a report on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3308,
     "status": "ok",
     "timestamp": 1613654527016,
     "user": {
      "displayName": "Abhijeet Athipet",
      "photoUrl": "",
      "userId": "03842398259045874555"
     },
     "user_tz": -330
    },
    "id": "vXnGiGIKxzE5",
    "outputId": "f5012768-1cb5-414c-f7c1-b369d0ebf43f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 16 11  4  3]\n",
      " [11 71  1 17  0]\n",
      " [10  6 64  2 18]\n",
      " [ 4  4  2 89  1]\n",
      " [ 4  4 46  7 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daisy       0.69      0.66      0.68       100\n",
      "   dandelion       0.70      0.71      0.71       100\n",
      "        rose       0.52      0.64      0.57       100\n",
      "   sunflower       0.75      0.89      0.81       100\n",
      "       tulip       0.64      0.39      0.48       100\n",
      "\n",
      "    accuracy                           0.66       500\n",
      "   macro avg       0.66      0.66      0.65       500\n",
      "weighted avg       0.66      0.66      0.65       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-initalizing the test data generator with shuffle=False to create the confusion matrix\n",
    "test_set = test_datagen.flow_from_directory('./flowers/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "# Predict the whole generator to get predictions\n",
    "Y_pred = classifier.predict_generator(test_set, int(500/32+1))\n",
    "\n",
    "# Find out the predictions classes with maximum probability\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Utilities for confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Printing the confusion matrix based on the actual data vs predicted data. \n",
    "print(confusion_matrix(test_set.classes, y_pred))\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(test_set.classes, y_pred, target_names=prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnp5BHrHWIuY"
   },
   "source": [
    "**We can play around with the model by adding regularization to the layers, adding more convolutional layers, etc., to improve the testing accuracy**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cv_week1_mentor_casestudy_flowers_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
